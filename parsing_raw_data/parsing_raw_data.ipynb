{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Raw Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: 25/08/2019\n",
    "\n",
    "Environment: Python 3.6.0 and Anaconda 4.3.0 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* pandas 0.19.2 (for data frame,reading/writing csv included in Anaconda Python 3.6) \n",
    "* re 2.2.1 (for regular expression, included in Anaconda Python 3.6) \n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "*Task is to analyse textual data, i.e., extracting data from the given semi-structured text files.XML text file contains information about several patent grants, e.g., patent title, patent ID, citation network, abstract etc.\n",
    "Our task is to extract the data and transform the data into the CSV and JSON format.There are a total of 150 patents in file named `Group055.txt`. The required tasks are the following:*\n",
    "\n",
    "1. Extract 'grant_id', 'patent_title', 'kind', 'no_of_claims', 'inventors','citation_applicant_count','citation_examiner_count', 'claim_text' and 'abstract from each patent.\n",
    "2. Load the features related to each patent into .csv and .json format files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glimpse of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<us-patent-grant lang=\"EN\" dtd-version=\"v4.5 2014-04-03\" file=\"US10357251-20190723.XML\" status=\"PRODUCTION\" id=\"us-patent-grant\" country=\"US\" date-produced=\"20190709\" date-publ=\"20190723\">\n",
      "<us-bibliographic-data-grant>\n",
      "<publication-reference>\n",
      "<document-id>\n",
      "<country>US</country>\n",
      "<doc-number>10357251</doc-number>\n",
      "<kind>B2</kind>\n",
      "<date>20190723</date>\n",
      "</document-id>\n"
     ]
    }
   ],
   "source": [
    "# print first ten lines of the file\n",
    "with open('Group055.txt','r') as infile:\n",
    "    print('\\n'.join([infile.readline().strip() for i in range(0, 10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first XML document has an XML declaration <?xml...?> and a root tag <us-patent-grant>. Based on this information it's possible to properly delimit an XML document so it can be extracted individually.<br>Input data is in XML format. The features to be extracted from the data are enclosed within certain tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "patent_split_data = open('Group055.txt','r',encoding='UTF-8').read().split('<?xml version=\"1.0\" encoding=\"UTF-8\"?>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each patent is represented by tag <'?xml version=\"1.0\" encoding=\"UTF-8\"?>'. So we split by that tag to get a list of patents.<br>\n",
    "NOTE: Value at zero(0) index of the list will be blank, so we dont consider that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Functions to extract features from a single patent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods used in feature extraction functions: <br>\n",
    "*  <font size= '3'> **re.sub(x,y,z)**   :   Replaces y with x in z.Operation is done on strings and return value is a string \n",
    "* **re.findall(x,y)**   :   Finds x pattern/string in y and returns the matches in a list\n",
    "* **zip()**     :    Returns a zip object, which is an iterator of tuples where the first item in each passed iterator is paired together,and then the second item in each passed iterator are paired together\n",
    "* **len()**    :    The len() function returns the number of items in an object.\n",
    "* **value_counts()**    :    function returns object containing counts of unique values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Function to extract Citation counts from each patent** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citation_counts(each_patent):\n",
    "    cited_by = re.findall(r'<category>cited by (.*)</category>',each_patent)\n",
    "    if len(cited_by)!=0:  # check for cited_by value. If null we return 0\n",
    "        citation_counts = pd.value_counts(cited_by)\n",
    "        return citation_counts\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used** :< category>cited by (.*)</ category>. <br> The regex with .findall() method will return a list of 'examiner' and 'applicant' strings <br> .value_counts() gives the unique value counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Function to extract claim text and count of claims for each patent** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claimText_and_count(each_patent):\n",
    "    pattern = re.compile('<claim id=\"[A-Za-z0-9\\S]+ num=\"[0-9]+\">\\\\n<claim-text>(.*)</claim-text>',re.DOTALL)# dotall includes \\n \n",
    "    claims_xml = ''.join(re.findall(pattern,each_patent)) # join and findall return match in string format \n",
    "    claims_no_tags = re.sub('<[^<]+>','',claims_xml) # remove xml tags\n",
    "    claims_text = re.sub('\\n','',claims_no_tags) # remove new line(\\n) from the text \n",
    "    claims_text = re.sub('\\t','',claims_text) # remove tabs(\\t) from the text\n",
    "    if len(claims_text)!=0: # check if claim text was extracted else we return 0\n",
    "        claim_id = re.findall('<claim id=\"[A-Za-z0-9\\S]+ num=\"([\\d]+)\">',each_patent) # extract claim id's\n",
    "        no_of_claims = len(claim_id) # number of claim id's\n",
    "        return claims_text,no_of_claims\n",
    "    else:\n",
    "        return 'NA',0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** < claim id=\"[A-Za-z0-9\\S]+ num=\"[0-9]+\">\\\\\\n<claim-text> (.\\*) </ claim-text> for *Claim Text* <br>\n",
    "  &emsp; &emsp;&emsp;&emsp;&emsp;&emsp;         < claim id=\"[A-Za-z0-9\\S]+ num=\"([\\d]+)\">  for *Claim Count* <br> Claim text is extracted using the pattern and tags, newline char(\\n) and tabs (\\t) are substituted with nothing using re.sub() <br> For count of claim id's we extarct all the claim id's into a list using re.findall() and then apply len() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Function to extract abstract for each patent** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstract(each_patent):\n",
    "    abstract_tags = ''.join(re.findall('<abstract id=\"abstract\">\\\\n<p id=\"[A-Za-z0-9\\S]+ num=\"[0-9]+\">(.*)</p>',each_patent))\n",
    "    abstract = re.sub('<[^<]+>','',abstract_tags)\n",
    "    abstract = re.sub('\\n','',abstract)\n",
    "    if len(abstract)!=0:\n",
    "        return abstract\n",
    "    else:\n",
    "        abstract='NA'\n",
    "        return abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** < abstract id=\"abstract\">\\\\n<p id=\"[A-Za-z0-9\\S]+ num=\"[0-9]+\">(.*) < /p> <br> Abstract text is extracted using the regex. Then all the tags and new line characters within the text have been removed. Default value 'NA' is returned in case of null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Function to extract grand id for each patent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grant_id(each_patent):\n",
    "    return ''.join(re.findall('file=\"([A-Za-z0-9]+)-[\\d]+.XML',each_patent)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** 'file=\"([A-Za-z0-9]+)-[\\d]+.XML' <br> Grant id has been extracted using above regex pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Function to extract title of each patent** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patent_title(each_patent):\n",
    "    return re.sub('<[^<]+>','',''.join(re.findall('<invention-title id=\"[A-Za-z0-9\\S]+>(.*)</invention-title>',each_patent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** <invention-title id=\"[A-Za-z0-9\\S]+>(.*) < /invention-title> <br> Patent title has been extracted from the invention title tags. Further unneccessary tags were removed using re.sub () method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Function to extract full names of all the inventors from each patent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inventors(each_patent):\n",
    "    xml_inventors_data = ''.join(re.findall('<inventors>[A-Za-z\\\\n\\S\\W]+</inventors>',each_patent))\n",
    "    if len(xml_inventors_data)!=0:\n",
    "        last_name = re.findall('<last-name>([A-Za-z\\s\\S]+?)</last-name>',xml_inventors_data)\n",
    "        first_name = re.findall('<first-name>([A-Za-z\\s\\S]+?)</first-name>',xml_inventors_data)\n",
    "        names = []\n",
    "#         names= ''\n",
    "        for first,last in list(zip(first_name,last_name)):\n",
    "            names.append(first+' '+last)\n",
    "        return names \n",
    "    else:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** <inventors>[A-Za-z\\\\n\\S\\W]+</inventors> - regex used to extract inventor details <br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <last-name>([A-Za-z\\s\\S]+?)</last-name>' - regex used to extract last name from inventor details text. <br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <first-name>([A-Za-z\\s\\S]+?)</first-name> - regex used to extract first name from inventor details text. <br> First name and last name of inventors are embedded in the inventor tags. <br> re.findall () method is used to extract the names into a list. Tuples of first and last names are created using zip () function. <br> Tuples are unpacked and appended into a list.<br> Return value of the function is the created list and default return value is 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Function to extract the kind code for each patent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kind(each_patent):\n",
    "    kind_tags = ''.join(re.findall('<publication-reference>([\\W\\w]+)</publication-reference>',each_patent))\n",
    "    kind = ''.join(re.findall('<kind>(.*)</kind>',kind_tags))\n",
    "    return kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regex used :** < publication-reference>([\\W\\w]+)</ publication-reference> - regex is used to extract text between < publication-reference>  &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; and < /publication-reference> <br> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;< kind>(.*)</ kind> - regex is used to extract kind code embedded within kind tags. <br> The extracted kind code is returned as a string value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calling functions for return values and creating a data frame for csv and a dictionary for &emsp; &emsp; json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods used: <br>\n",
    "*  <font size= '3'> **re.sub(x,y,z)**   :   Replaces y with x in z.Operation is done on strings and return value is a string \n",
    "* **re.findall(x,y)**   :   Finds x pattern/string in y and returns the matches in a list\n",
    "* **zip()**     :    Returns a zip object, which is an iterator of tuples where the first item in each passed iterator is paired together,and then the second item in each passed iterator are paired together\n",
    "* **len()**    :    The len() function returns the number of items in an object.\n",
    "* **value_counts()**    :    function returns object containing counts of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# column[] contains the names of all the columns to be used for the data frame\n",
    "column=['grant_id','patent_title','kind','no_of_claims','inventors','citation_applicant_count','citation_examiner_count','claim_text','abstract']\n",
    "df = pd.DataFrame(columns=column)  # created a data frame using pandas pd\n",
    "d_frame=df.iloc[0:0]   # re-setting a new data frame to avoid overloading on multiple code runs \n",
    "dict_for_json = {}     # dictionary to be written for json output\n",
    "# dictionary build to hold values for each kind code\n",
    "kind_dictionary = {\"B2\":\"Utility Patent Grant (with a published application) issued on or after January 2, 2001.\",\"B1\":\"Utility Patent Grant (no published application) issued on or after January 2, 2001.\",'E1':'Reissue Patent','S1':'Design Patent',\"P2\":\"Plant Patent Grant (no published application) issued on or after January 2, 2001\",\"P3\":\"Plant Patent Grant (with published application) issued on or after January 2, 2001\"}\n",
    "\n",
    "'''''\n",
    "loop will run for each patent in the patent_split_data. For each patent the loop extracts all the features\n",
    "using the above defined functions. Features are saved in a list and after converting to a series, list is \n",
    "appended to a data frame. Feature list values are used to create a dictionary which is used later for writing into json format.\n",
    "\n",
    "'''''\n",
    "for i in range(1,len(patent_split_data)):\n",
    "    dict_json = {} \n",
    "    grant_id = get_grant_id(patent_split_data[i])\n",
    "    patent_title = get_patent_title(patent_split_data[i])\n",
    "    kind_code =get_kind(patent_split_data[i])\n",
    "    if kind_code in kind_dictionary.keys():\n",
    "        kind = kind_dictionary[kind_code]\n",
    "    else:\n",
    "        kind = 'NA'\n",
    "        \n",
    "    claim_text,no_of_claims = get_claimText_and_count(patent_split_data[i])\n",
    "    inventors = '[{}]'.format(','.join(get_inventors(patent_split_data[i])))\n",
    "    citation_counts= get_citation_counts(patent_split_data[i])\n",
    "    \n",
    "    # limiting conditions for citation_counts.Set default values as 0\n",
    "    if 'examiner' in citation_counts:\n",
    "        citation_examiner_count = citation_counts['examiner']\n",
    "    else:\n",
    "        citation_examiner_count=0\n",
    "        \n",
    "    if 'applicant' in citation_counts:\n",
    "        citation_applicant_count = citation_counts['applicant']\n",
    "    else:\n",
    "        citation_applicant_count=0         \n",
    "    abstract = get_abstract(patent_split_data[i])\n",
    "    \n",
    "    # list stores all features for each patent\n",
    "    all_patent_feature = [grant_id,patent_title,kind,no_of_claims,inventors,citation_applicant_count,citation_examiner_count,claim_text,abstract]\n",
    "    # populate dataframe with all_patent_features\n",
    "    d_frame = d_frame.append(pd.Series(all_patent_feature,index=column),ignore_index=True)\n",
    "    \n",
    "    # This loop populates the dictionary with key,value pairs required to generate json format text file \n",
    "    for i in range(1,len(column)):\n",
    "        dict_json[column[i]]=all_patent_feature[i] # \n",
    "    dict_for_json[grant_id] = dict_json # dictionary with grand id's as keys and respective other features as values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glimpse of the data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grant_id</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>kind</th>\n",
       "      <th>no_of_claims</th>\n",
       "      <th>inventors</th>\n",
       "      <th>citation_applicant_count</th>\n",
       "      <th>citation_examiner_count</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US10357251</td>\n",
       "      <td>Surgical staples comprising hardness variation...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>19</td>\n",
       "      <td>[Frederick E. Shelton, IV,Jeffrey S. Swayze,Ch...</td>\n",
       "      <td>4653</td>\n",
       "      <td>15</td>\n",
       "      <td>1. A surgical staple cartridge for use with a ...</td>\n",
       "      <td>A surgical staple cartridge is disclosed compr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10358657</td>\n",
       "      <td>IS-targeting system for gene insertion and gen...</td>\n",
       "      <td>Utility Patent Grant (with a published applica...</td>\n",
       "      <td>12</td>\n",
       "      <td>[R&amp;#xe9;mi Bernard,Esther Gerber,Elena Hauser,...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1. A method for introducing a nucleic acid mol...</td>\n",
       "      <td>The present invention relates to methods and c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     grant_id                                       patent_title  \\\n",
       "0  US10357251  Surgical staples comprising hardness variation...   \n",
       "1  US10358657  IS-targeting system for gene insertion and gen...   \n",
       "\n",
       "                                                kind no_of_claims  \\\n",
       "0  Utility Patent Grant (with a published applica...           19   \n",
       "1  Utility Patent Grant (with a published applica...           12   \n",
       "\n",
       "                                           inventors citation_applicant_count  \\\n",
       "0  [Frederick E. Shelton, IV,Jeffrey S. Swayze,Ch...                     4653   \n",
       "1  [R&#xe9;mi Bernard,Esther Gerber,Elena Hauser,...                        8   \n",
       "\n",
       "  citation_examiner_count                                         claim_text  \\\n",
       "0                      15  1. A surgical staple cartridge for use with a ...   \n",
       "1                       0  1. A method for introducing a nucleic acid mol...   \n",
       "\n",
       "                                            abstract  \n",
       "0  A surgical staple cartridge is disclosed compr...  \n",
       "1  The present invention relates to methods and c...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Writing into csv and json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing output into a json text file\n",
    "with open('Group055.json', 'w+') as f:\n",
    "    json_text = ''\n",
    "    # formatting the key, value pairs of the dictionary for .json format\n",
    "    for s,v in dict_for_json.items():\n",
    "        first = '{%s}' % ','.join(['\"%s\": \"%s\"' % (x, y) for x, y in v.items()]) # placing all key, values pairs in double quotes\n",
    "        second = '%s' % ''.join('\"%s\": %s' % (s, first))  # creating new key,value pairs.Key= grand_id, values=all other features\n",
    "        json_text = json_text+second+','  # writing key,value pairs from second as string into json_text\n",
    "\n",
    "    json_text_1 = re.sub('([\\W\\w\\S\\s]+})(\\W)',r'\\1',json_text)  # removing the last unneccessary '}' bracket from the text\n",
    "    json_text_final = '{' +json_text_1+ '}' # enclosing the json text in {}\n",
    "    print(json_text_final,file=f)\n",
    "    \n",
    "# writing output of d_frame dictionary into a csv file   \n",
    "d_frame.to_csv('Group055.csv',mode='w+',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('Group055.json') as f:\n",
    "#     d = json.load(f)\n",
    "#     print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_fr = pd.read_csv('Group055.csv')\n",
    "# data_fr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <br>\n",
    "* Pandas 0.25.1 documentation https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "* re - Regular Expression Opeartions https://docs.python.org/2/library/re.html\n",
    "* re - Regular Expression Operations https://docs.python.org/3/library/re.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
